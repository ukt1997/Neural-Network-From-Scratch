{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "\n",
    "# SciKitLearn is a machine learning utilities library\n",
    "import sklearn\n",
    "\n",
    "# The sklearn dataset module helps generating datasets\n",
    "import sklearn.datasets\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(show = False):\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    Y = iris.target\n",
    "    Y = Y.reshape(-1,1)\n",
    "    if show : \n",
    "        print(\"X contains input and Y contains output ,each row is for one datapoint \\ntotal datapoints = \",X.shape[0])\n",
    "        print(\"Shape of X = \",X.shape)\n",
    "        print(\"Shape of Y = \",Y.shape)\n",
    "        print(\"OneHotEncoding started \")\n",
    "    Y1 = np.zeros((Y.shape[0],3))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y1[i][Y[i][0]] = 1\n",
    "    Y = Y1\n",
    "    if show : print(\"final shape of Y = \",Y.shape)\n",
    "    return X,Y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X contains input and Y contains output ,each row is for one datapoint \n",
      "total datapoints =  150\n",
      "Shape of X =  (150, 4)\n",
      "Shape of Y =  (150, 1)\n",
      "OneHotEncoding started \n",
      "final shape of Y =  (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Loading Data into X and Y\n",
    "X,Y = load_data(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is used as config file containing all global variables for model\n",
    "# no of layers is all hidden + output layer \n",
    "\n",
    "no_of_layers = 2\n",
    "\n",
    "# no_of_features is input dimension \n",
    "\n",
    "no_of_features = X.shape[1]\n",
    "\n",
    "no_of_data_points = X.shape[0]\n",
    "\n",
    "# output_nodes is a list of nodes in each hidden and output layer 1-by-1\n",
    "\n",
    "output_nodes =[5,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_initi(show = False):\n",
    "    if show : print(\"Weight Initialization started \")\n",
    "    inp_size = no_of_features\n",
    "    param_dict = {}\n",
    "    for index,cur_op in enumerate(output_nodes):\n",
    "        W_val = np.random.rand(inp_size,cur_op)\n",
    "        W_key = \"W\"+str(index)\n",
    "        if show : print(\"shape of \",W_key,\" is \" ,W_val.shape)\n",
    "        B_val = np.random.rand(1,cur_op)\n",
    "        B_key = \"b\"+str(index)\n",
    "        if show : print(\"shape of \",B_key,\" is \" ,B_val.shape)\n",
    "        inp_size = cur_op\n",
    "        param_dict[W_key] = W_val\n",
    "        param_dict[B_key] = B_val\n",
    "    if show : print(\"Weight Initialization Finished \")\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Initialization started \n",
      "shape of  W0  is  (4, 5)\n",
      "shape of  b0  is  (1, 5)\n",
      "shape of  W1  is  (5, 3)\n",
      "shape of  b1  is  (1, 3)\n",
      "Weight Initialization Finished \n",
      "{'W0': array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ],\n",
      "       [0.64589411, 0.43758721, 0.891773  , 0.96366276, 0.38344152],\n",
      "       [0.79172504, 0.52889492, 0.56804456, 0.92559664, 0.07103606],\n",
      "       [0.0871293 , 0.0202184 , 0.83261985, 0.77815675, 0.87001215]]), 'b0': array([[0.97861834, 0.79915856, 0.46147936, 0.78052918, 0.11827443]]), 'W1': array([[0.63992102, 0.14335329, 0.94466892],\n",
      "       [0.52184832, 0.41466194, 0.26455561],\n",
      "       [0.77423369, 0.45615033, 0.56843395],\n",
      "       [0.0187898 , 0.6176355 , 0.61209572],\n",
      "       [0.616934  , 0.94374808, 0.6818203 ]]), 'b1': array([[0.3595079 , 0.43703195, 0.6976312 ]])}\n"
     ]
    }
   ],
   "source": [
    "# Testing Weight_initialization function \n",
    "my_params = weight_initi(True)\n",
    "print(my_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax non-linearity , to be used in last layer of model \n",
    "def softmax(Arr,axis,show = False ):\n",
    "    arr = np.exp(Arr)\n",
    "    dir_one = 1\n",
    "    if axis == 1 : dir_one = arr.shape[0]\n",
    "    arr_sum = np.array(np.sum(arr,axis = axis)).reshape(dir_one,-1)\n",
    "    if show : print(arr_sum.shape)\n",
    "    if show : print(arr_sum)\n",
    "    arr = arr/arr_sum\n",
    "    return arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09003057, 0.24472847, 0.66524096],\n",
       "       [0.09003057, 0.24472847, 0.66524096]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing Softmax function \n",
    "arr = np.array([[1,2,3],[1,2,3]])\n",
    "softmax(arr,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed-Forward function \n",
    "def feed_forward(X,params,show = False):\n",
    "    A = X\n",
    "    params[\"A0\"] = A\n",
    "    if show : print(\"A0 shape = \",A.shape)\n",
    "    for i in range (no_of_layers):\n",
    "        wt_name = \"W\"+str(i)\n",
    "        bias_name = \"b\"+str(i)\n",
    "        wt = params[wt_name]\n",
    "        b = params[bias_name]\n",
    "        if show : print(wt_name,\" shape = \",wt.shape)\n",
    "        if show : print(bias_name,\" shape = \",b.shape)\n",
    "        Z = np.dot(A,wt)\n",
    "        Z_name = \"Z\"+str(i+1)\n",
    "        if show : print(Z_name,\" shape = \",Z.shape)\n",
    "        Z = Z + b\n",
    "        if show : print(Z_name,\" shape = \",Z.shape)\n",
    "        params[Z_name] = Z\n",
    "        A_name = \"A\"+str(i+1)\n",
    "        if i < no_of_layers -1 : \n",
    "            A = np.tanh(Z)\n",
    "        else :\n",
    "            A = softmax(Z,1)\n",
    "        if show : print(A_name,\" shape = \",A.shape)\n",
    "        params[A_name] = A\n",
    "    \n",
    "    return A,params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0 shape =  (150, 4)\n",
      "W0  shape =  (4, 5)\n",
      "b0  shape =  (1, 5)\n",
      "Z1  shape =  (150, 5)\n",
      "Z1  shape =  (150, 5)\n",
      "A1  shape =  (150, 5)\n",
      "W1  shape =  (5, 3)\n",
      "b1  shape =  (1, 3)\n",
      "Z2  shape =  (150, 3)\n",
      "Z2  shape =  (150, 3)\n",
      "A2  shape =  (150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Testing Feed forward function \n",
    "A,params = feed_forward(X,my_params,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['W0', 'b0', 'W1', 'b1', 'A0', 'Z1', 'A1', 'Z2', 'A2'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuction to update weights and biases \n",
    "def update_weights(params,error,learning_rate,show = False):\n",
    "    #print(params.keys())\n",
    "    DA = error \n",
    "    loop = no_of_layers\n",
    "    #print(\"Learning Rate = \",learning_rate)\n",
    "    for i in range(loop):\n",
    "        cur = loop - i -1 \n",
    "        wt_name = \"W\"+str(cur)\n",
    "        bias_name = \"b\"+str(cur)\n",
    "        z_name = \"Z\"+str(cur+1)\n",
    "        a_name = \"A\"+str(cur)\n",
    "        a_next_name = \"A\"+str(cur+1)\n",
    "        if show :\n",
    "            print(wt_name,\" \",bias_name,\" \",z_name,\" \",a_name)\n",
    "            print(\"DA shape = \",DA.shape)\n",
    "            print(z_name,\" shape = \",params[z_name].shape)\n",
    "            print(wt_name,\" shape = \",params[wt_name].shape)\n",
    "            print(bias_name,\" shape = \",params[bias_name].shape)\n",
    "            print(a_name,\" shape = \",params[a_name].shape)\n",
    "            print(a_next_name,\" shape = \",params[a_next_name].shape)\n",
    "        a = params[a_name]\n",
    "        a_next = params[a_next_name]\n",
    "        wt = params[wt_name]\n",
    "        #print(wt[0])\n",
    "        bias = params[bias_name]\n",
    "        #DZ = np.multiply(DA,der_sigmoid(params[z_name]))\n",
    "        if i == 0 : \n",
    "            DZ = DA\n",
    "        else:\n",
    "            D_tmp = 1 - np.multiply(a_next,a_next)\n",
    "            if show : print(\"A^2 shape = \",D_tmp.shape)\n",
    "            DZ = np.multiply(DA,D_tmp)\n",
    "        #print(\"DZ shape = \",DZ.shape)\n",
    "        #DW = 1/no_of_data_points * np.dot(DZ,a.T)\n",
    "        DW =  1/no_of_data_points * np.dot(a.T,DZ)\n",
    "        if show : print(\"DW shape = \",DW.shape)\n",
    "        DB = 1/no_of_data_points * np.sum(DZ,axis = 0).reshape(1,-1)\n",
    "        if show : print(\"DB shape = \",DB.shape)\n",
    "        #DA = 1/no_of_data_points * np.dot(wt.T,DZ)\n",
    "        DA =  np.dot(DZ,wt.T)\n",
    "        if show : print(\"DA shape = \",DA.shape)\n",
    "        wt = wt - learning_rate*DW\n",
    "        bias = bias - learning_rate*DB\n",
    "        params[wt_name] = wt\n",
    "        params[bias_name] = bias\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1   b1   Z2   A1\n",
      "DA shape =  (150, 3)\n",
      "Z2  shape =  (150, 3)\n",
      "W1  shape =  (5, 3)\n",
      "b1  shape =  (1, 3)\n",
      "A1  shape =  (150, 5)\n",
      "A2  shape =  (150, 3)\n",
      "DW shape =  (5, 3)\n",
      "DB shape =  (1, 3)\n",
      "DA shape =  (150, 5)\n",
      "W0   b0   Z1   A0\n",
      "DA shape =  (150, 5)\n",
      "Z1  shape =  (150, 5)\n",
      "W0  shape =  (4, 5)\n",
      "b0  shape =  (1, 5)\n",
      "A0  shape =  (150, 4)\n",
      "A1  shape =  (150, 5)\n",
      "A^2 shape =  (150, 5)\n",
      "DW shape =  (4, 5)\n",
      "DB shape =  (1, 5)\n",
      "DA shape =  (150, 4)\n"
     ]
    }
   ],
   "source": [
    "# Testing Update Function \n",
    "updated_params = update_weights(params,A-Y,0.01,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will calculate accuracy and print that along with correct prediction \n",
    "def calculate_acc(A,Y):\n",
    "    no_data_points = A.shape[0]\n",
    "    no_of_class = A.shape[1]\n",
    "    totla_correct = 0\n",
    "    for j in range(no_of_data_points):\n",
    "        maxv = A[j][0]\n",
    "        ind = 0\n",
    "        for i in range(no_of_class):\n",
    "            if maxv < A[j][i] :\n",
    "                maxv = A[j][i]\n",
    "                ind = i\n",
    "        if Y[j][ind] == 1:\n",
    "            totla_correct = totla_correct + 1\n",
    "    acc =  ( totla_correct / no_of_data_points ) * 100\n",
    "    print(\"correct pre = \",totla_correct)\n",
    "    print(\"Accuracy = \",acc,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all Togather to create training function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return final trained model \n",
    "def train_model(X,Y,iterations,learning_rate = 0.01):\n",
    "    cur_params = weight_initi()\n",
    "    for i in range(iterations):\n",
    "        print(\"Iteration \",i+1)\n",
    "        a_out,cur_params = feed_forward(X,cur_params)\n",
    "        #print(a_out)\n",
    "        #error = calculate_mse(a_out,Y)\n",
    "        calculate_acc(a_out,Y)\n",
    "        #DA = np.multiply(a_out-Y,a_out-Y)\n",
    "        DA = a_out - Y\n",
    "        cur_params = update_weights(cur_params,DA,learning_rate)\n",
    "    return cur_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only one layer with 3 nodes i.e no Hidden layer \n",
      "145/150 correct \n"
     ]
    }
   ],
   "source": [
    "print(\"Using only one layer with 3 nodes i.e no Hidden layer \")\n",
    "#my_final_params = train_model(X,Y,2000,0.01)\n",
    "#print(my_final_params)\n",
    "print(\"145/150 correct \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using two layers [5,3] i.e one Hidden layer \n",
      "Iteration  1\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  2\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  3\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  4\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  5\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  6\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  7\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  8\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  9\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  10\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  11\n",
      "correct pre =  50\n",
      "Accuracy =  33.33333333333333 %\n",
      "Iteration  12\n",
      "correct pre =  49\n",
      "Accuracy =  32.666666666666664 %\n",
      "Iteration  13\n",
      "correct pre =  48\n",
      "Accuracy =  32.0 %\n",
      "Iteration  14\n",
      "correct pre =  44\n",
      "Accuracy =  29.333333333333332 %\n",
      "Iteration  15\n",
      "correct pre =  33\n",
      "Accuracy =  22.0 %\n",
      "Iteration  16\n",
      "correct pre =  23\n",
      "Accuracy =  15.333333333333332 %\n",
      "Iteration  17\n",
      "correct pre =  17\n",
      "Accuracy =  11.333333333333332 %\n",
      "Iteration  18\n",
      "correct pre =  12\n",
      "Accuracy =  8.0 %\n",
      "Iteration  19\n",
      "correct pre =  41\n",
      "Accuracy =  27.333333333333332 %\n",
      "Iteration  20\n",
      "correct pre =  58\n",
      "Accuracy =  38.666666666666664 %\n",
      "Iteration  21\n",
      "correct pre =  59\n",
      "Accuracy =  39.33333333333333 %\n",
      "Iteration  22\n",
      "correct pre =  60\n",
      "Accuracy =  40.0 %\n",
      "Iteration  23\n",
      "correct pre =  60\n",
      "Accuracy =  40.0 %\n",
      "Iteration  24\n",
      "correct pre =  60\n",
      "Accuracy =  40.0 %\n",
      "Iteration  25\n",
      "correct pre =  60\n",
      "Accuracy =  40.0 %\n",
      "Iteration  26\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  27\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  28\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  29\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  30\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  31\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  32\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  33\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  34\n",
      "correct pre =  61\n",
      "Accuracy =  40.666666666666664 %\n",
      "Iteration  35\n",
      "correct pre =  62\n",
      "Accuracy =  41.333333333333336 %\n",
      "Iteration  36\n",
      "correct pre =  62\n",
      "Accuracy =  41.333333333333336 %\n",
      "Iteration  37\n",
      "correct pre =  64\n",
      "Accuracy =  42.66666666666667 %\n",
      "Iteration  38\n",
      "correct pre =  65\n",
      "Accuracy =  43.333333333333336 %\n",
      "Iteration  39\n",
      "correct pre =  65\n",
      "Accuracy =  43.333333333333336 %\n",
      "Iteration  40\n",
      "correct pre =  66\n",
      "Accuracy =  44.0 %\n",
      "Iteration  41\n",
      "correct pre =  66\n",
      "Accuracy =  44.0 %\n",
      "Iteration  42\n",
      "correct pre =  67\n",
      "Accuracy =  44.666666666666664 %\n",
      "Iteration  43\n",
      "correct pre =  66\n",
      "Accuracy =  44.0 %\n",
      "Iteration  44\n",
      "correct pre =  66\n",
      "Accuracy =  44.0 %\n",
      "Iteration  45\n",
      "correct pre =  66\n",
      "Accuracy =  44.0 %\n",
      "Iteration  46\n",
      "correct pre =  68\n",
      "Accuracy =  45.33333333333333 %\n",
      "Iteration  47\n",
      "correct pre =  68\n",
      "Accuracy =  45.33333333333333 %\n",
      "Iteration  48\n",
      "correct pre =  71\n",
      "Accuracy =  47.333333333333336 %\n",
      "Iteration  49\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  50\n",
      "correct pre =  78\n",
      "Accuracy =  52.0 %\n",
      "Iteration  51\n",
      "correct pre =  79\n",
      "Accuracy =  52.666666666666664 %\n",
      "Iteration  52\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  53\n",
      "correct pre =  82\n",
      "Accuracy =  54.666666666666664 %\n",
      "Iteration  54\n",
      "correct pre =  84\n",
      "Accuracy =  56.00000000000001 %\n",
      "Iteration  55\n",
      "correct pre =  86\n",
      "Accuracy =  57.333333333333336 %\n",
      "Iteration  56\n",
      "correct pre =  87\n",
      "Accuracy =  57.99999999999999 %\n",
      "Iteration  57\n",
      "correct pre =  86\n",
      "Accuracy =  57.333333333333336 %\n",
      "Iteration  58\n",
      "correct pre =  83\n",
      "Accuracy =  55.333333333333336 %\n",
      "Iteration  59\n",
      "correct pre =  77\n",
      "Accuracy =  51.33333333333333 %\n",
      "Iteration  60\n",
      "correct pre =  75\n",
      "Accuracy =  50.0 %\n",
      "Iteration  61\n",
      "correct pre =  73\n",
      "Accuracy =  48.66666666666667 %\n",
      "Iteration  62\n",
      "correct pre =  72\n",
      "Accuracy =  48.0 %\n",
      "Iteration  63\n",
      "correct pre =  72\n",
      "Accuracy =  48.0 %\n",
      "Iteration  64\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  65\n",
      "correct pre =  75\n",
      "Accuracy =  50.0 %\n",
      "Iteration  66\n",
      "correct pre =  78\n",
      "Accuracy =  52.0 %\n",
      "Iteration  67\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  68\n",
      "correct pre =  79\n",
      "Accuracy =  52.666666666666664 %\n",
      "Iteration  69\n",
      "correct pre =  79\n",
      "Accuracy =  52.666666666666664 %\n",
      "Iteration  70\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  71\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  72\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  73\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  74\n",
      "correct pre =  82\n",
      "Accuracy =  54.666666666666664 %\n",
      "Iteration  75\n",
      "correct pre =  83\n",
      "Accuracy =  55.333333333333336 %\n",
      "Iteration  76\n",
      "correct pre =  83\n",
      "Accuracy =  55.333333333333336 %\n",
      "Iteration  77\n",
      "correct pre =  84\n",
      "Accuracy =  56.00000000000001 %\n",
      "Iteration  78\n",
      "correct pre =  82\n",
      "Accuracy =  54.666666666666664 %\n",
      "Iteration  79\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  80\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  81\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  82\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  83\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  84\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  85\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  86\n",
      "correct pre =  83\n",
      "Accuracy =  55.333333333333336 %\n",
      "Iteration  87\n",
      "correct pre =  82\n",
      "Accuracy =  54.666666666666664 %\n",
      "Iteration  88\n",
      "correct pre =  82\n",
      "Accuracy =  54.666666666666664 %\n",
      "Iteration  89\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  90\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  91\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  92\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  93\n",
      "correct pre =  80\n",
      "Accuracy =  53.333333333333336 %\n",
      "Iteration  94\n",
      "correct pre =  81\n",
      "Accuracy =  54.0 %\n",
      "Iteration  95\n",
      "correct pre =  77\n",
      "Accuracy =  51.33333333333333 %\n",
      "Iteration  96\n",
      "correct pre =  77\n",
      "Accuracy =  51.33333333333333 %\n",
      "Iteration  97\n",
      "correct pre =  77\n",
      "Accuracy =  51.33333333333333 %\n",
      "Iteration  98\n",
      "correct pre =  77\n",
      "Accuracy =  51.33333333333333 %\n",
      "Iteration  99\n",
      "correct pre =  76\n",
      "Accuracy =  50.66666666666667 %\n",
      "Iteration  100\n",
      "correct pre =  75\n",
      "Accuracy =  50.0 %\n",
      "Iteration  101\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  102\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  103\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  104\n",
      "correct pre =  74\n",
      "Accuracy =  49.333333333333336 %\n",
      "Iteration  105\n",
      "correct pre =  73\n",
      "Accuracy =  48.66666666666667 %\n",
      "Iteration  106\n",
      "correct pre =  72\n",
      "Accuracy =  48.0 %\n",
      "Iteration  107\n",
      "correct pre =  72\n",
      "Accuracy =  48.0 %\n",
      "Iteration  108\n",
      "correct pre =  72\n",
      "Accuracy =  48.0 %\n",
      "Iteration  109\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  110\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  111\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  112\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  113\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  114\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  115\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  116\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  117\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  118\n",
      "correct pre =  117\n",
      "Accuracy =  78.0 %\n",
      "Iteration  119\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  120\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  121\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  122\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  123\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  124\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  125\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  126\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  127\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  128\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  129\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  130\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  131\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  132\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  133\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  134\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  135\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  136\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  137\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  138\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  139\n",
      "correct pre =  123\n",
      "Accuracy =  82.0 %\n",
      "Iteration  140\n",
      "correct pre =  124\n",
      "Accuracy =  82.66666666666667 %\n",
      "Iteration  141\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  142\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  143\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  144\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  145\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  146\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  147\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  148\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  149\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  150\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  151\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  152\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  153\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  154\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  155\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  156\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  157\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  158\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  159\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  160\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  161\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  162\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  163\n",
      "correct pre =  129\n",
      "Accuracy =  86.0 %\n",
      "Iteration  164\n",
      "correct pre =  129\n",
      "Accuracy =  86.0 %\n",
      "Iteration  165\n",
      "correct pre =  131\n",
      "Accuracy =  87.33333333333333 %\n",
      "Iteration  166\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  167\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  168\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  169\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  170\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  171\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  172\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  173\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  174\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  175\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  176\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  177\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  178\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  179\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  180\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  181\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  182\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  183\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  184\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  185\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  186\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  187\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  188\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  189\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  190\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  191\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  192\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  193\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  194\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  195\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  196\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  197\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  198\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  199\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  200\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  201\n",
      "correct pre =  135\n",
      "Accuracy =  90.0 %\n",
      "Iteration  202\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  203\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  204\n",
      "correct pre =  129\n",
      "Accuracy =  86.0 %\n",
      "Iteration  205\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  206\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  207\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  208\n",
      "correct pre =  114\n",
      "Accuracy =  76.0 %\n",
      "Iteration  209\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  210\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  211\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  212\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  213\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  214\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  215\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  216\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  217\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  218\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  219\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  220\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  221\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  222\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  223\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  224\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  225\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  226\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  227\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  228\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  229\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  230\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  231\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  232\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  233\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  234\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  235\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  236\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  237\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  238\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  239\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  240\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  241\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  242\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  243\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  244\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  245\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  246\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  247\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  248\n",
      "correct pre =  118\n",
      "Accuracy =  78.66666666666666 %\n",
      "Iteration  249\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  250\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  251\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  252\n",
      "correct pre =  116\n",
      "Accuracy =  77.33333333333333 %\n",
      "Iteration  253\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  254\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  255\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  256\n",
      "correct pre =  114\n",
      "Accuracy =  76.0 %\n",
      "Iteration  257\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  258\n",
      "correct pre =  131\n",
      "Accuracy =  87.33333333333333 %\n",
      "Iteration  259\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  260\n",
      "correct pre =  115\n",
      "Accuracy =  76.66666666666667 %\n",
      "Iteration  261\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  262\n",
      "correct pre =  126\n",
      "Accuracy =  84.0 %\n",
      "Iteration  263\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  264\n",
      "correct pre =  110\n",
      "Accuracy =  73.33333333333333 %\n",
      "Iteration  265\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  266\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  267\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  268\n",
      "correct pre =  121\n",
      "Accuracy =  80.66666666666666 %\n",
      "Iteration  269\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  270\n",
      "correct pre =  111\n",
      "Accuracy =  74.0 %\n",
      "Iteration  271\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  272\n",
      "correct pre =  131\n",
      "Accuracy =  87.33333333333333 %\n",
      "Iteration  273\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  274\n",
      "correct pre =  111\n",
      "Accuracy =  74.0 %\n",
      "Iteration  275\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  276\n",
      "correct pre =  131\n",
      "Accuracy =  87.33333333333333 %\n",
      "Iteration  277\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  278\n",
      "correct pre =  109\n",
      "Accuracy =  72.66666666666667 %\n",
      "Iteration  279\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  280\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  281\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  282\n",
      "correct pre =  124\n",
      "Accuracy =  82.66666666666667 %\n",
      "Iteration  283\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  284\n",
      "correct pre =  104\n",
      "Accuracy =  69.33333333333334 %\n",
      "Iteration  285\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  286\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  287\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  288\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  289\n",
      "correct pre =  116\n",
      "Accuracy =  77.33333333333333 %\n",
      "Iteration  290\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  291\n",
      "correct pre =  123\n",
      "Accuracy =  82.0 %\n",
      "Iteration  292\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  293\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  294\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  295\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  296\n",
      "correct pre =  123\n",
      "Accuracy =  82.0 %\n",
      "Iteration  297\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  298\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  299\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  300\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  301\n",
      "correct pre =  124\n",
      "Accuracy =  82.66666666666667 %\n",
      "Iteration  302\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  303\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  304\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  305\n",
      "correct pre =  146\n",
      "Accuracy =  97.33333333333334 %\n",
      "Iteration  306\n",
      "correct pre =  114\n",
      "Accuracy =  76.0 %\n",
      "Iteration  307\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  308\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  309\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  310\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  311\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  312\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  313\n",
      "correct pre =  120\n",
      "Accuracy =  80.0 %\n",
      "Iteration  314\n",
      "correct pre =  146\n",
      "Accuracy =  97.33333333333334 %\n",
      "Iteration  315\n",
      "correct pre =  110\n",
      "Accuracy =  73.33333333333333 %\n",
      "Iteration  316\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  317\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  318\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  319\n",
      "correct pre =  119\n",
      "Accuracy =  79.33333333333333 %\n",
      "Iteration  320\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  321\n",
      "correct pre =  110\n",
      "Accuracy =  73.33333333333333 %\n",
      "Iteration  322\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  323\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  324\n",
      "correct pre =  146\n",
      "Accuracy =  97.33333333333334 %\n",
      "Iteration  325\n",
      "correct pre =  114\n",
      "Accuracy =  76.0 %\n",
      "Iteration  326\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  327\n",
      "correct pre =  123\n",
      "Accuracy =  82.0 %\n",
      "Iteration  328\n",
      "correct pre =  135\n",
      "Accuracy =  90.0 %\n",
      "Iteration  329\n",
      "correct pre =  102\n",
      "Accuracy =  68.0 %\n",
      "Iteration  330\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  331\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  332\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  333\n",
      "correct pre =  137\n",
      "Accuracy =  91.33333333333333 %\n",
      "Iteration  334\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  335\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  336\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  337\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  338\n",
      "correct pre =  115\n",
      "Accuracy =  76.66666666666667 %\n",
      "Iteration  339\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  340\n",
      "correct pre =  137\n",
      "Accuracy =  91.33333333333333 %\n",
      "Iteration  341\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  342\n",
      "correct pre =  104\n",
      "Accuracy =  69.33333333333334 %\n",
      "Iteration  343\n",
      "correct pre =  137\n",
      "Accuracy =  91.33333333333333 %\n",
      "Iteration  344\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  345\n",
      "correct pre =  104\n",
      "Accuracy =  69.33333333333334 %\n",
      "Iteration  346\n",
      "correct pre =  135\n",
      "Accuracy =  90.0 %\n",
      "Iteration  347\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  348\n",
      "correct pre =  105\n",
      "Accuracy =  70.0 %\n",
      "Iteration  349\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  350\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  351\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  352\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  353\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  354\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  355\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  356\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  357\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  358\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  359\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  360\n",
      "correct pre =  109\n",
      "Accuracy =  72.66666666666667 %\n",
      "Iteration  361\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  362\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  363\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  364\n",
      "correct pre =  137\n",
      "Accuracy =  91.33333333333333 %\n",
      "Iteration  365\n",
      "correct pre =  104\n",
      "Accuracy =  69.33333333333334 %\n",
      "Iteration  366\n",
      "correct pre =  127\n",
      "Accuracy =  84.66666666666667 %\n",
      "Iteration  367\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  368\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  369\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  370\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  371\n",
      "correct pre =  105\n",
      "Accuracy =  70.0 %\n",
      "Iteration  372\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  373\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  374\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  375\n",
      "correct pre =  135\n",
      "Accuracy =  90.0 %\n",
      "Iteration  376\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  377\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  378\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  379\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  380\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  381\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  382\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  383\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  384\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  385\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  386\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  387\n",
      "correct pre =  134\n",
      "Accuracy =  89.33333333333333 %\n",
      "Iteration  388\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  389\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  390\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  391\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  392\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  393\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  394\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  395\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  396\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  397\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  398\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  399\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  400\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  401\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  402\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  403\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  404\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  405\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  406\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  407\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  408\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  409\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  410\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  411\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  412\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  413\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  414\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  415\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  416\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  417\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  418\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  419\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  420\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  421\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  422\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  423\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  424\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  425\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  426\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  427\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  428\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  429\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  430\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  431\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  432\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  433\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  434\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  435\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  436\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  437\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  438\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  439\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  440\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  441\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  442\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  443\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  444\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  445\n",
      "correct pre =  140\n",
      "Accuracy =  93.33333333333333 %\n",
      "Iteration  446\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  447\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  448\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  449\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  450\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  451\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  452\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  453\n",
      "correct pre =  133\n",
      "Accuracy =  88.66666666666667 %\n",
      "Iteration  454\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  455\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  456\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  457\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  458\n",
      "correct pre =  107\n",
      "Accuracy =  71.33333333333334 %\n",
      "Iteration  459\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  460\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  461\n",
      "correct pre =  105\n",
      "Accuracy =  70.0 %\n",
      "Iteration  462\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  463\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  464\n",
      "correct pre =  107\n",
      "Accuracy =  71.33333333333334 %\n",
      "Iteration  465\n",
      "correct pre =  139\n",
      "Accuracy =  92.66666666666666 %\n",
      "Iteration  466\n",
      "correct pre =  136\n",
      "Accuracy =  90.66666666666666 %\n",
      "Iteration  467\n",
      "correct pre =  104\n",
      "Accuracy =  69.33333333333334 %\n",
      "Iteration  468\n",
      "correct pre =  125\n",
      "Accuracy =  83.33333333333334 %\n",
      "Iteration  469\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  470\n",
      "correct pre =  115\n",
      "Accuracy =  76.66666666666667 %\n",
      "Iteration  471\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  472\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  473\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  474\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  475\n",
      "correct pre =  131\n",
      "Accuracy =  87.33333333333333 %\n",
      "Iteration  476\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  477\n",
      "correct pre =  100\n",
      "Accuracy =  66.66666666666666 %\n",
      "Iteration  478\n",
      "correct pre =  102\n",
      "Accuracy =  68.0 %\n",
      "Iteration  479\n",
      "correct pre =  113\n",
      "Accuracy =  75.33333333333333 %\n",
      "Iteration  480\n",
      "correct pre =  143\n",
      "Accuracy =  95.33333333333334 %\n",
      "Iteration  481\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  482\n",
      "correct pre =  113\n",
      "Accuracy =  75.33333333333333 %\n",
      "Iteration  483\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  484\n",
      "correct pre =  145\n",
      "Accuracy =  96.66666666666667 %\n",
      "Iteration  485\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  486\n",
      "correct pre =  144\n",
      "Accuracy =  96.0 %\n",
      "Iteration  487\n",
      "correct pre =  110\n",
      "Accuracy =  73.33333333333333 %\n",
      "Iteration  488\n",
      "correct pre =  142\n",
      "Accuracy =  94.66666666666667 %\n",
      "Iteration  489\n",
      "correct pre =  146\n",
      "Accuracy =  97.33333333333334 %\n",
      "Iteration  490\n",
      "correct pre =  122\n",
      "Accuracy =  81.33333333333333 %\n",
      "Iteration  491\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  492\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  493\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "Iteration  494\n",
      "correct pre =  128\n",
      "Accuracy =  85.33333333333334 %\n",
      "Iteration  495\n",
      "correct pre =  101\n",
      "Accuracy =  67.33333333333333 %\n",
      "Iteration  496\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  497\n",
      "correct pre =  132\n",
      "Accuracy =  88.0 %\n",
      "Iteration  498\n",
      "correct pre =  141\n",
      "Accuracy =  94.0 %\n",
      "Iteration  499\n",
      "correct pre =  106\n",
      "Accuracy =  70.66666666666667 %\n",
      "Iteration  500\n",
      "correct pre =  138\n",
      "Accuracy =  92.0 %\n",
      "{'W0': array([[-0.61902568,  0.66512817,  0.67093348,  0.20630582,  0.12900967],\n",
      "       [-0.56435958,  0.36251843,  0.57042252,  0.43580459,  0.98812901],\n",
      "       [ 0.9187114 ,  0.20857156,  0.16133882,  0.65205393,  0.25388613],\n",
      "       [ 1.18403904,  0.24442245,  0.15895951,  0.1102365 ,  0.65655994]]), 'b0': array([[-0.20390226,  0.19622786,  0.36879127,  0.82014349,  0.09707901]]), 'W1': array([[-2.54644706,  0.99974162,  3.45720822],\n",
      "       [ 0.35936277,  1.12355367,  0.56734137],\n",
      "       [ 0.63027923,  0.18578985,  0.24518926],\n",
      "       [ 0.00949731,  0.4439407 ,  0.08162647],\n",
      "       [ 0.20805458,  0.56127709,  0.02706201]]), 'b1': array([[0.58356084, 0.71317131, 0.22773092]]), 'A0': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'Z1': array([[-3.25450454,  5.19809173,  6.04469554,  4.33258   ,  4.70022802],\n",
      "       [-2.87906908,  4.88380608,  5.62529769,  4.07341396,  4.18036156],\n",
      "       [-2.97246789,  4.80242691,  5.58906163,  4.05410793,  4.32679714],\n",
      "       [-2.67071165,  4.74137634,  5.49719382,  4.1203071 ,  4.26586023],\n",
      "       [-3.25276779,  5.16783072,  6.03464445,  4.35552974,  4.78614004],\n",
      "       [-3.10123353,  5.65409436,  6.55433802,  4.78646013,  5.34165972],\n",
      "       [-2.80708311,  4.85371726,  5.66808261,  4.19686762,  4.6025665 ],\n",
      "       [-3.04962062,  5.11618399,  5.93669385,  4.33357367,  4.61390264],\n",
      "       [-2.55156078,  4.51498937,  5.23278881,  3.92667792,  4.0170441 ],\n",
      "       [-2.95524731,  4.91647296,  5.68257786,  4.17117659,  4.23890701],\n",
      "       [-3.42852959,  5.49099165,  6.37619388,  4.54684023,  4.96194505],\n",
      "       [-2.84299995,  5.00401526,  5.81864107,  4.35751706,  4.6134893 ],\n",
      "       [-2.94410804,  4.79285089,  5.54230841,  4.04175925,  4.10180471],\n",
      "       [-2.96035412,  4.39771462,  5.15844013,  3.74298749,  3.9611348 ],\n",
      "       [-4.09805552,  5.80322779,  6.76729228,  4.56449029,  5.23382207],\n",
      "       [-3.72528781,  5.99317862,  7.00856144,  4.93584622,  5.82365015],\n",
      "       [-3.48872281,  5.57066569,  6.4898025 ,  4.52563813,  5.24010587],\n",
      "       [-3.13459141,  5.22253397,  6.06059149,  4.34360366,  4.76588396],\n",
      "       [-3.33263177,  5.79293903,  6.68267982,  4.79374884,  5.21589356],\n",
      "       [-3.19713135,  5.35214698,  6.24785209,  4.53955153,  5.08771121],\n",
      "       [-3.07537269,  5.42395014,  6.23733493,  4.54650887,  4.71628319],\n",
      "       [-3.0240808 ,  5.34033727,  6.2067058 ,  4.5069944 ,  5.05455422],\n",
      "       [-3.42076037,  4.81835024,  5.70173562,  4.01218353,  4.63298257],\n",
      "       [-2.49787334,  5.26148606,  6.02670056,  4.47410592,  4.77573536],\n",
      "       [-2.55238299,  5.06658677,  5.86704271,  4.55313357,  4.68965468],\n",
      "       [-2.74019862,  4.99203337,  5.72465878,  4.22445602,  4.24403939],\n",
      "       [-2.71292204,  5.18592564,  5.98461963,  4.42082649,  4.77060298],\n",
      "       [-3.2125064 ,  5.28546185,  6.12792275,  4.41841656,  4.73851738],\n",
      "       [-3.2562413 ,  5.22835273,  6.05474663,  4.30963027,  4.61431599],\n",
      "       [-2.68185093,  4.86499841,  5.63746327,  4.24972444,  4.40296253],\n",
      "       [-2.68358769,  4.89525942,  5.64751436,  4.2267747 ,  4.31705051],\n",
      "       [-3.02929107,  5.43112028,  6.23685907,  4.43814519,  4.79681814],\n",
      "       [-3.65124405,  5.4785313 ,  6.45428023,  4.66887762,  5.26573902],\n",
      "       [-3.84596319,  5.71790717,  6.71236452,  4.72016972,  5.44352214],\n",
      "       [-2.83533418,  4.9409152 ,  5.69847381,  4.18220025,  4.30456295],\n",
      "       [-3.23396274,  4.98110859,  5.77420774,  4.05079558,  4.3401114 ],\n",
      "       [-3.57087357,  5.44328637,  6.29693498,  4.3498987 ,  4.72644317],\n",
      "       [-3.31780674,  5.07687553,  5.95165517,  4.32387503,  4.7075832 ],\n",
      "       [-2.70157052,  4.53038415,  5.27369717,  3.9050532 ,  4.09046857],\n",
      "       [-3.1044948 ,  5.18269695,  6.00378718,  4.35420472,  4.62680355],\n",
      "       [-3.17658956,  5.13516385,  5.97736428,  4.25776711,  4.72759459],\n",
      "       [-2.26456962,  4.36757571,  4.95739078,  3.6316424 ,  3.4773349 ],\n",
      "       [-2.80784537,  4.60288805,  5.38778165,  3.99221478,  4.28809443],\n",
      "       [-2.5262332 ,  5.27106207,  6.07345377,  4.4864546 ,  5.00072779],\n",
      "       [-2.68972894,  5.46001789,  6.32828355,  4.8113972 ,  5.254921  ],\n",
      "       [-2.70428178,  4.84173537,  5.57410032,  4.06380657,  4.23311659],\n",
      "       [-3.22017216,  5.34856191,  6.24809001,  4.59373337,  5.04744373],\n",
      "       [-2.8207214 ,  4.75677112,  5.53810218,  4.09868238,  4.3392847 ],\n",
      "       [-3.37365542,  5.42447869,  6.30910055,  4.52620918,  4.94904415],\n",
      "       [-3.09335552,  5.05907488,  5.86351774,  4.22478738,  4.48970125],\n",
      "       [ 0.49804254,  7.33467541,  7.8715115 ,  6.87789311,  6.27459695],\n",
      "       [ 0.75345609,  6.9183256 ,  7.45257972,  6.63471946,  6.21207053],\n",
      "       [ 0.91971191,  7.29806709,  7.79553964,  6.95511594,  6.27931598],\n",
      "       [ 1.0013726 ,  5.84027118,  6.22289832,  5.70873808,  4.94839183],\n",
      "       [ 1.00800392,  6.86068793,  7.30763797,  6.54623287,  5.85510818],\n",
      "       [ 1.11029875,  6.25884267,  6.72296556,  6.29393163,  5.5952006 ],\n",
      "       [ 1.06885062,  6.95422118,  7.49069234,  6.79910387,  6.41441542],\n",
      "       [ 0.23963459,  5.25811852,  5.71675558,  5.13902307,  4.59511228],\n",
      "       [ 0.66016606,  6.91456835,  7.39998164,  6.58839738,  5.83551014],\n",
      "       [ 0.97648625,  5.78932519,  6.24954936,  5.76698624,  5.34520831],\n",
      "       [ 0.59105474,  5.22133801,  5.58794771,  5.11574197,  4.26353839],\n",
      "       [ 0.84348485,  6.45068544,  6.95462696,  6.24878613,  5.87377476],\n",
      "       [ 0.42039974,  6.06325727,  6.45363487,  5.73524157,  4.71711561],\n",
      "       [ 1.15132239,  6.627303  ,  7.09654482,  6.56147129,  5.86205001],\n",
      "       [ 0.24018461,  6.04086715,  6.56770956,  5.73003185,  5.45261646],\n",
      "       [ 0.42518553,  7.0363131 ,  7.56478764,  6.57680267,  6.06091591],\n",
      "       [ 1.29872434,  6.31371809,  6.80174861,  6.38250948,  5.91123743],\n",
      "       [ 0.36133331,  6.13234828,  6.62079328,  5.9770889 ,  5.21076691],\n",
      "       [ 1.39457865,  6.42278022,  6.74797068,  6.15764949,  5.19813942],\n",
      "       [ 0.503525  ,  5.90954638,  6.35615034,  5.72927788,  5.00221825],\n",
      "       [ 1.67818333,  6.72165907,  7.21320256,  6.7602517 ,  6.42069921],\n",
      "       [ 0.40644043,  6.42060863,  6.91066948,  6.05042833,  5.51986191],\n",
      "       [ 1.5677815 ,  6.68147769,  7.05072624,  6.56984491,  5.60903297],\n",
      "       [ 0.96463355,  6.54216657,  7.00771068,  6.49584318,  5.6319252 ],\n",
      "       [ 0.47929745,  6.71897094,  7.21739334,  6.35151877,  5.73354294],\n",
      "       [ 0.53319713,  6.9335482 ,  7.44065207,  6.51259083,  5.94920208],\n",
      "       [ 0.9172129 ,  7.07749888,  7.52528977,  6.72751336,  5.87893188],\n",
      "       [ 1.41929627,  7.19853089,  7.65223653,  6.95752587,  6.31140158],\n",
      "       [ 1.13236506,  6.54351795,  7.01307969,  6.4214529 ,  5.86402812],\n",
      "       [-0.11188902,  5.90444037,  6.39985444,  5.52164405,  4.9467223 ],\n",
      "       [ 0.51466427,  5.78592431,  6.2158809 ,  5.59986054,  4.86511596],\n",
      "       [ 0.29787882,  5.7406249 ,  6.18385107,  5.52363138,  4.77407155],\n",
      "       [ 0.40741493,  6.13951842,  6.62031743,  5.86872522,  5.29130186],\n",
      "       [ 1.93978696,  6.62059931,  7.01169444,  6.73654799,  5.88438898],\n",
      "       [ 1.40847269,  6.18069219,  6.66756195,  6.34124738,  5.88543562],\n",
      "       [ 0.98659108,  6.74921993,  7.31418683,  6.6503805 ,  6.42374871],\n",
      "       [ 0.83571562,  7.12332685,  7.62908523,  6.78344283,  6.20273724],\n",
      "       [ 0.94986847,  6.45580347,  6.82418047,  6.1346085 ,  5.15315292],\n",
      "       [ 0.6714088 ,  6.18140494,  6.70542119,  6.09964015,  5.67837171],\n",
      "       [ 0.89509776,  5.91277508,  6.33698279,  5.79589966,  5.14601769],\n",
      "       [ 1.10953649,  6.00801346,  6.4426646 ,  6.08927879,  5.28072853],\n",
      "       [ 1.00131265,  6.64269778,  7.13745318,  6.53984658,  5.93547448],\n",
      "       [ 0.55742467,  6.12412364,  6.57940907,  5.89034994,  5.21787739],\n",
      "       [ 0.23789784,  5.28837952,  5.72680667,  5.11607333,  4.50920025],\n",
      "       [ 0.92769338,  6.09350626,  6.55042836,  6.03410329,  5.40732138],\n",
      "       [ 0.59349381,  6.24433282,  6.77275245,  6.17445304,  5.65100513],\n",
      "       [ 0.76654436,  6.23252311,  6.73160616,  6.14189591,  5.61784814],\n",
      "       [ 0.5890458 ,  6.58594504,  7.08320669,  6.31025667,  5.70774113],\n",
      "       [-0.09395501,  5.3892671 ,  5.87547879,  5.03927311,  4.70921757],\n",
      "       [ 0.72280946,  6.17541399,  6.65843005,  6.03310962,  5.49364675],\n",
      "       [ 3.40740897,  7.44534453,  7.84349632,  7.74598834,  7.33536888],\n",
      "       [ 2.4092747 ,  6.56090012,  6.92519563,  6.72835688,  6.05555498],\n",
      "       [ 2.55130298,  7.75006617,  8.12939856,  7.67099424,  6.85412511],\n",
      "       [ 2.39307745,  7.04581238,  7.4395202 ,  7.23367756,  6.37897174],\n",
      "       [ 2.90358885,  7.35457353,  7.72660066,  7.4930261 ,  6.81698716],\n",
      "       [ 2.95503835,  8.22863111,  8.57780236,  8.23058801,  7.09634887],\n",
      "       [ 2.18835694,  5.71575217,  6.07867602,  6.04223551,  5.45817833],\n",
      "       [ 2.52244194,  7.85694208,  8.22339064,  7.89642658,  6.68570003],\n",
      "       [ 2.57987508,  7.20857073,  7.51199232,  7.27228961,  6.08610056],\n",
      "       [ 2.85100144,  8.17357411,  8.63459688,  8.12761567,  7.77330428],\n",
      "       [ 1.8793815 ,  7.23219277,  7.69595608,  7.10170183,  6.70558191],\n",
      "       [ 2.27377429,  7.00169217,  7.36002337,  6.98255419,  6.18373734],\n",
      "       [ 2.32843622,  7.46709864,  7.86358306,  7.34827908,  6.71386855],\n",
      "       [ 2.59346453,  6.42546835,  6.7437799 ,  6.56638241,  5.8852957 ],\n",
      "       [ 2.95570294,  6.71936327,  7.06171763,  6.82705597,  6.48264761],\n",
      "       [ 2.48773971,  7.28072087,  7.70881836,  7.24455277,  6.94042574],\n",
      "       [ 2.13331936,  7.19423306,  7.61461522,  7.25331494,  6.47819802],\n",
      "       [ 2.69185025,  8.63045905,  9.13326342,  8.67609453,  7.99079762],\n",
      "       [ 3.64315708,  8.26159226,  8.49692027,  8.29455974,  6.92147532],\n",
      "       [ 1.98868861,  6.39404016,  6.69445342,  6.44241489,  5.29927992],\n",
      "       [ 2.60085811,  7.69671431,  8.10882052,  7.60853003,  7.10648412],\n",
      "       [ 2.39205412,  6.44685407,  6.83167941,  6.61128822,  6.14344512],\n",
      "       [ 2.9833982 ,  8.21905509,  8.53104914,  8.21823933,  6.87135644],\n",
      "       [ 1.82124605,  6.82730831,  7.21249857,  6.69007747,  6.00362664],\n",
      "       [ 2.41764278,  7.55105587,  7.9998842 ,  7.5888014 ,  7.04818336],\n",
      "       [ 2.12728689,  7.83661347,  8.27902239,  7.81092139,  6.89307252],\n",
      "       [ 1.72611048,  6.77619013,  7.1863136 ,  6.6478217 ,  6.06415021],\n",
      "       [ 1.77158214,  6.80303825,  7.24943863,  6.77955773,  6.27426362],\n",
      "       [ 2.75108009,  7.14940011,  7.49725914,  7.2437988 ,  6.49002753],\n",
      "       [ 1.79999083,  7.67351075,  8.10087825,  7.57130148,  6.51335786],\n",
      "       [ 2.44687367,  7.86993099,  8.21706993,  7.7540895 ,  6.61466701],\n",
      "       [ 2.05165867,  8.65202897,  9.18725654,  8.4996928 ,  7.80912216],\n",
      "       [ 2.87099322,  7.17384235,  7.51315509,  7.25482247,  6.55568347],\n",
      "       [ 1.60211388,  6.83194787,  7.25412071,  6.83099827,  5.95624868],\n",
      "       [ 2.18258555,  6.70626167,  7.07062302,  7.01757844,  5.79410738],\n",
      "       [ 2.65562883,  8.2397427 ,  8.59601819,  7.94723888,  7.11361935],\n",
      "       [ 2.84686914,  7.37372556,  7.8201071 ,  7.51772346,  7.26697203],\n",
      "       [ 2.13505611,  7.16397206,  7.60456412,  7.27626468,  6.56411004],\n",
      "       [ 1.72958399,  6.71566813,  7.16621142,  6.69372117,  6.23597426],\n",
      "       [ 2.12355231,  7.54900637,  7.97158474,  7.34728542,  6.80019392],\n",
      "       [ 2.78678469,  7.53102153,  7.9173537 ,  7.4695053 ,  7.02213686],\n",
      "       [ 2.0727616 ,  7.53531935,  7.95497501,  7.17371624,  6.85534041],\n",
      "       [ 2.4092747 ,  6.56090012,  6.92519563,  6.72835688,  6.05555498],\n",
      "       [ 2.84947693,  7.67191569,  8.07399495,  7.71830999,  7.14436014],\n",
      "       [ 2.8972953 ,  7.64882483,  8.063468  ,  7.63289604,  7.31080712],\n",
      "       [ 2.3325197 ,  7.38689866,  7.77987999,  7.15407885,  6.75611414],\n",
      "       [ 2.14430634,  6.80010382,  7.13044392,  6.67914506,  5.89704519],\n",
      "       [ 2.08252866,  7.18054604,  7.59800548,  7.07974576,  6.53334451],\n",
      "       [ 2.58808554,  7.24105603,  7.70485006,  7.35565775,  7.13763826],\n",
      "       [ 2.07507513,  6.71172668,  7.14751973,  6.86870663,  6.29923874]]), 'A1': array([[-0.99702452,  0.9999389 ,  0.99998876,  0.99965508,  0.99983464],\n",
      "       [-0.9937059 ,  0.99988545,  0.999974  ,  0.99942086,  0.99953236],\n",
      "       [-0.99477554,  0.99986521,  0.99997205,  0.99939807,  0.99965106],\n",
      "       [-0.99046755,  0.9998477 ,  0.99996641,  0.99947269,  0.99960585],\n",
      "       [-0.99701418,  0.99993509,  0.99998853,  0.99967055,  0.99986074],\n",
      "       [-0.99595932,  0.99997546,  0.99999594,  0.99986083,  0.99995415],\n",
      "       [-0.99273479,  0.99987835,  0.99997613,  0.99954754,  0.99979898],\n",
      "       [-0.99552091,  0.99992803,  0.99998605,  0.99965576,  0.99980348],\n",
      "       [-0.98791794,  0.9997605 ,  0.999943  ,  0.99922341,  0.99935177],\n",
      "       [-0.99459297,  0.9998927 ,  0.99997682,  0.99952369,  0.99958402],\n",
      "       [-0.9978982 ,  0.99996599,  0.99999421,  0.99977528,  0.99990202],\n",
      "       [-0.99323667,  0.99990993,  0.99998234,  0.99967185,  0.99980332],\n",
      "       [-0.99447149,  0.9998626 ,  0.99996931,  0.99938302,  0.99945282],\n",
      "       [-0.99464776,  0.9996972 ,  0.99993386,  0.99887884,  0.99927511],\n",
      "       [-0.9994487 ,  0.99998179,  0.99999735,  0.99978307,  0.99994312],\n",
      "       [-0.99883846,  0.99998754,  0.99999837,  0.99989677,  0.99998251],\n",
      "       [-0.99813637,  0.999971  ,  0.99999539,  0.99976554,  0.99994383],\n",
      "       [-0.99621961,  0.99994182,  0.99998911,  0.9996626 ,  0.99985499],\n",
      "       [-0.9974544 ,  0.99998141,  0.99999686,  0.99986285,  0.99994104],\n",
      "       [-0.99666334,  0.9999551 ,  0.99999251,  0.99977198,  0.99992381],\n",
      "       [-0.99574529,  0.99996111,  0.99999236,  0.99977513,  0.99983987],\n",
      "       [-0.99528673,  0.99995403,  0.99999187,  0.99975664,  0.99991859],\n",
      "       [-0.99786533,  0.99986943,  0.99997769,  0.99934544,  0.99981084],\n",
      "       [-0.98655763,  0.99994618,  0.99998835,  0.9997401 ,  0.99985782],\n",
      "       [-0.98793767,  0.99992052,  0.99998397,  0.99977809,  0.99983111],\n",
      "       [-0.99169925,  0.99990775,  0.99997869,  0.99957183,  0.99958827],\n",
      "       [-0.99123587,  0.9999374 ,  0.99998733,  0.99971087,  0.99985635],\n",
      "       [-0.99676422,  0.9999487 ,  0.99999049,  0.99970948,  0.99984683],\n",
      "       [-0.99703482,  0.99994249,  0.99998899,  0.99963888,  0.99980364],\n",
      "       [-0.99067659,  0.99988106,  0.99997463,  0.99959292,  0.99970036],\n",
      "       [-0.99070877,  0.99988805,  0.99997513,  0.99957381,  0.9996442 ],\n",
      "       [-0.99533548,  0.99996166,  0.99999235,  0.99972072,  0.99986369],\n",
      "       [-0.99865319,  0.99996513,  0.99999505,  0.99982394,  0.99994664],\n",
      "       [-0.99908742,  0.9999784 ,  0.99999704,  0.99984111,  0.9999626 ],\n",
      "       [-0.99313254,  0.99989782,  0.99997754,  0.99953408,  0.9996352 ],\n",
      "       [-0.99689993,  0.99990571,  0.9999807 ,  0.99939407,  0.99966023],\n",
      "       [-0.99841852,  0.99996259,  0.99999321,  0.99966682,  0.99984309],\n",
      "       [-0.9973779 ,  0.99992214,  0.99998646,  0.99964902,  0.99983706],\n",
      "       [-0.99103553,  0.99976776,  0.99994748,  0.9991891 ,  0.99944028],\n",
      "       [-0.99598554,  0.99993699,  0.9999878 ,  0.99966967,  0.99980849],\n",
      "       [-0.99652365,  0.99993071,  0.99998714,  0.99959942,  0.99984345],\n",
      "       [-0.97865044,  0.99967839,  0.99990113,  0.99859938,  0.99809348],\n",
      "       [-0.99274582,  0.99979911,  0.99995819,  0.99931878,  0.99962299],\n",
      "       [-0.98729415,  0.9999472 ,  0.99998939,  0.99974643,  0.99990934],\n",
      "       [-0.99082167,  0.99996382,  0.99999363,  0.9998676 ,  0.99994547],\n",
      "       [-0.99108379,  0.9998754 ,  0.9999712 ,  0.99940963,  0.99957918],\n",
      "       [-0.99681337,  0.99995478,  0.99999252,  0.99979539,  0.99991742],\n",
      "       [-0.99292959,  0.99985232,  0.99996905,  0.9994494 ,  0.99965967],\n",
      "       [-0.99765469,  0.99996115,  0.99999338,  0.99976581,  0.99989946],\n",
      "       [-0.99589528,  0.99991932,  0.99998385,  0.99957211,  0.99974808],\n",
      "       [ 0.46057633,  0.99999915,  0.99999971,  0.99999788,  0.9999929 ],\n",
      "       [ 0.63720628,  0.99999804,  0.99999933,  0.99999655,  0.99999196],\n",
      "       [ 0.7257611 ,  0.99999908,  0.99999966,  0.99999818,  0.99999297],\n",
      "       [ 0.76217001,  0.99998309,  0.99999213,  0.999978  ,  0.99989933],\n",
      "       [ 0.76493516,  0.9999978 ,  0.9999991 ,  0.99999588,  0.99998358],\n",
      "       [ 0.80416797,  0.99999268,  0.99999711,  0.99999317,  0.99997239],\n",
      "       [ 0.7890278 ,  0.99999818,  0.99999938,  0.99999751,  0.99999464],\n",
      "       [ 0.23515058,  0.99994582,  0.99997835,  0.99993124,  0.99979596],\n",
      "       [ 0.57847391,  0.99999803,  0.99999925,  0.99999621,  0.99998292],\n",
      "       [ 0.7515408 ,  0.99998127,  0.99999254,  0.99998042,  0.99995448],\n",
      "       [ 0.53065377,  0.99994168,  0.99997198,  0.99992797,  0.99960401],\n",
      "       [ 0.68765046,  0.99999501,  0.99999818,  0.99999253,  0.99998418],\n",
      "       [ 0.39726714,  0.99998917,  0.99999504,  0.99997913,  0.99984013],\n",
      "       [ 0.81819168,  0.9999965 ,  0.99999863,  0.999996  ,  0.99998381],\n",
      "       [ 0.23567011,  0.99998868,  0.99999605,  0.99997891,  0.99996328],\n",
      "       [ 0.40128995,  0.99999845,  0.99999946,  0.99999612,  0.99998912],\n",
      "       [ 0.8613944 ,  0.99999344,  0.99999753,  0.99999428,  0.99998532],\n",
      "       [ 0.34638791,  0.99999057,  0.99999645,  0.99998714,  0.99994043],\n",
      "       [ 0.88417417,  0.99999472,  0.99999725,  0.99999103,  0.99993891],\n",
      "       [ 0.46488486,  0.99998527,  0.99999397,  0.99997888,  0.99990961],\n",
      "       [ 0.93262541,  0.9999971 ,  0.99999891,  0.99999731,  0.9999947 ],\n",
      "       [ 0.38544612,  0.9999947 ,  0.99999801,  0.99998889,  0.9999679 ],\n",
      "       [ 0.91667216,  0.99999686,  0.9999985 ,  0.99999607,  0.99997314],\n",
      "       [ 0.74633655,  0.99999584,  0.99999836,  0.99999544,  0.99997434],\n",
      "       [ 0.44568078,  0.99999708,  0.99999892,  0.99999392,  0.99997906],\n",
      "       [ 0.4878212 ,  0.9999981 ,  0.99999931,  0.99999559,  0.9999864 ],\n",
      "       [ 0.72457624,  0.99999858,  0.99999942,  0.99999713,  0.99998435],\n",
      "       [ 0.88945202,  0.99999888,  0.99999955,  0.99999819,  0.99999341],\n",
      "       [ 0.81182715,  0.99999586,  0.99999838,  0.99999471,  0.99998387],\n",
      "       [-0.11142443,  0.99998512,  0.99999448,  0.99996801,  0.999899  ],\n",
      "       [ 0.4735714 ,  0.99998114,  0.99999202,  0.99997264,  0.99988109],\n",
      "       [ 0.28937024,  0.99997936,  0.99999149,  0.99996814,  0.99985734],\n",
      "       [ 0.38627553,  0.9999907 ,  0.99999645,  0.99998402,  0.99994929],\n",
      "       [ 0.95951711,  0.99999645,  0.99999838,  0.99999718,  0.99998451],\n",
      "       [ 0.88716936,  0.99999144,  0.99999677,  0.99999379,  0.99998455],\n",
      "       [ 0.755905  ,  0.99999725,  0.99999911,  0.99999665,  0.99999473],\n",
      "       [ 0.6835331 ,  0.9999987 ,  0.99999953,  0.99999744,  0.99999181],\n",
      "       [ 0.7397235 ,  0.99999506,  0.99999764,  0.99999061,  0.99993316],\n",
      "       [ 0.58590582,  0.99999145,  0.999997  ,  0.99998993,  0.99997662],\n",
      "       [ 0.71390249,  0.99998537,  0.99999374,  0.99998152,  0.9999322 ],\n",
      "       [ 0.80389849,  0.99998791,  0.99999493,  0.99998972,  0.99994821],\n",
      "       [ 0.76214488,  0.9999966 ,  0.99999874,  0.99999583,  0.99998602],\n",
      "       [ 0.50606415,  0.99999041,  0.99999614,  0.9999847 ,  0.99994127],\n",
      "       [ 0.23350919,  0.999949  ,  0.99997878,  0.99992801,  0.99975771],\n",
      "       [ 0.72951666,  0.99998981,  0.99999591,  0.99998852,  0.99995979],\n",
      "       [ 0.53240374,  0.99999246,  0.99999738,  0.99999133,  0.9999753 ],\n",
      "       [ 0.64491556,  0.99999228,  0.99999716,  0.99999075,  0.99997361],\n",
      "       [ 0.52920899,  0.99999619,  0.99999859,  0.99999339,  0.99997795],\n",
      "       [-0.09367952,  0.99995832,  0.99998424,  0.99991606,  0.99983759],\n",
      "       [ 0.61864653,  0.99999135,  0.99999671,  0.9999885 ,  0.99996617],\n",
      "       [ 0.99780762,  0.99999932,  0.99999969,  0.99999963,  0.99999915],\n",
      "       [ 0.98397248,  0.999996  ,  0.99999807,  0.99999714,  0.999989  ],\n",
      "       [ 0.98791175,  0.99999963,  0.99999983,  0.99999957,  0.99999777],\n",
      "       [ 0.98344915,  0.99999848,  0.99999931,  0.99999896,  0.99999424],\n",
      "       [ 0.99400621,  0.99999918,  0.99999961,  0.99999938,  0.9999976 ],\n",
      "       [ 0.99459071,  0.99999986,  0.99999993,  0.99999986,  0.99999863],\n",
      "       [ 0.97517875,  0.9999783 ,  0.9999895 ,  0.99998871,  0.99996368],\n",
      "       [ 0.98719806,  0.9999997 ,  0.99999986,  0.99999972,  0.99999688],\n",
      "       [ 0.98857932,  0.9999989 ,  0.9999994 ,  0.99999904,  0.99998966],\n",
      "       [ 0.99334369,  0.99999984,  0.99999994,  0.99999983,  0.99999965],\n",
      "       [ 0.95443707,  0.99999895,  0.99999959,  0.99999864,  0.999997  ],\n",
      "       [ 0.9790358 ,  0.99999834,  0.99999919,  0.99999828,  0.99999149],\n",
      "       [ 0.98118642,  0.99999935,  0.9999997 ,  0.99999917,  0.99999705],\n",
      "       [ 0.98888384,  0.99999475,  0.99999722,  0.99999604,  0.99998454],\n",
      "       [ 0.99459788,  0.99999708,  0.99999853,  0.99999765,  0.99999532],\n",
      "       [ 0.98628429,  0.99999905,  0.9999996 ,  0.99999898,  0.99999813],\n",
      "       [ 0.97233045,  0.99999887,  0.99999951,  0.999999  ,  0.99999528],\n",
      "       [ 0.99086035,  0.99999994,  0.99999998,  0.99999994,  0.99999977],\n",
      "       [ 0.99863124,  0.99999987,  0.99999992,  0.99999988,  0.99999805],\n",
      "       [ 0.96321965,  0.99999441,  0.99999694,  0.99999493,  0.9999501 ],\n",
      "       [ 0.98904611,  0.99999959,  0.99999982,  0.99999951,  0.99999866],\n",
      "       [ 0.98341552,  0.99999497,  0.99999767,  0.99999638,  0.99999078],\n",
      "       [ 0.99488822,  0.99999985,  0.99999992,  0.99999985,  0.99999785],\n",
      "       [ 0.94896251,  0.99999765,  0.99999891,  0.99999691,  0.9999878 ],\n",
      "       [ 0.98423639,  0.99999945,  0.99999977,  0.99999949,  0.99999849],\n",
      "       [ 0.9719993 ,  0.99999969,  0.99999987,  0.99999967,  0.99999794],\n",
      "       [ 0.93859461,  0.9999974 ,  0.99999885,  0.99999664,  0.99998919],\n",
      "       [ 0.94378257,  0.99999753,  0.99999899,  0.99999742,  0.9999929 ],\n",
      "       [ 0.99187722,  0.99999877,  0.99999938,  0.99999898,  0.99999539],\n",
      "       [ 0.94680506,  0.99999957,  0.99999982,  0.99999947,  0.9999956 ],\n",
      "       [ 0.98512488,  0.99999971,  0.99999985,  0.99999963,  0.99999641],\n",
      "       [ 0.96750123,  0.99999994,  0.99999998,  0.99999992,  0.99999967],\n",
      "       [ 0.99360374,  0.99999883,  0.9999994 ,  0.999999  ,  0.99999596],\n",
      "       [ 0.92198613,  0.99999767,  0.999999  ,  0.99999767,  0.99998659],\n",
      "       [ 0.9748942 ,  0.99999701,  0.99999856,  0.99999839,  0.99998145],\n",
      "       [ 0.99017705,  0.99999986,  0.99999993,  0.99999975,  0.99999867],\n",
      "       [ 0.99328863,  0.99999921,  0.99999968,  0.99999941,  0.99999902],\n",
      "       [ 0.97242508,  0.9999988 ,  0.9999995 ,  0.99999904,  0.99999602],\n",
      "       [ 0.93900675,  0.99999706,  0.99999881,  0.99999693,  0.99999233],\n",
      "       [ 0.97179234,  0.99999945,  0.99999976,  0.99999917,  0.99999752],\n",
      "       [ 0.99243492,  0.99999943,  0.99999973,  0.99999935,  0.99999841],\n",
      "       [ 0.96882339,  0.99999943,  0.99999975,  0.99999883,  0.99999778],\n",
      "       [ 0.98397248,  0.999996  ,  0.99999807,  0.99999714,  0.999989  ],\n",
      "       [ 0.99332343,  0.99999957,  0.99999981,  0.9999996 ,  0.99999875],\n",
      "       [ 0.99393052,  0.99999955,  0.9999998 ,  0.99999953,  0.99999911],\n",
      "       [ 0.98133802,  0.99999923,  0.99999965,  0.99999878,  0.99999729],\n",
      "       [ 0.97292369,  0.99999752,  0.99999872,  0.99999684,  0.9999849 ],\n",
      "       [ 0.96941726,  0.99999884,  0.9999995 ,  0.99999858,  0.99999577],\n",
      "       [ 0.98876428,  0.99999897,  0.99999959,  0.99999918,  0.99999874],\n",
      "       [ 0.96896508,  0.99999704,  0.99999876,  0.99999784,  0.99999325]]), 'Z2': array([[ 4.31654934,  2.03572222, -2.29010576],\n",
      "       [ 4.30801802,  2.0387014 , -2.2787047 ],\n",
      "       [ 4.31075381,  2.03766601, -2.2824099 ],\n",
      "       [ 4.29978059,  2.04195788, -2.26753606],\n",
      "       [ 4.31652704,  2.03574978, -2.29007026],\n",
      "       [ 4.31388445,  2.0369878 , -2.28638354],\n",
      "       [ 4.30560334,  2.03987045, -2.27533595],\n",
      "       [ 4.31271384,  2.03719477, -2.28491979],\n",
      "       [ 4.29319709,  2.04414944, -2.25881245],\n",
      "       [ 4.3102895 ,  2.03789845, -2.28175397],\n",
      "       [ 4.31879891,  2.03497201, -2.293095  ],\n",
      "       [ 4.30689659,  2.03946336, -2.27703964],\n",
      "       [ 4.30993701,  2.03784826, -2.28136862],\n",
      "       [ 4.31026338,  2.0371553 , -2.28212684],\n",
      "       [ 4.32275779,  2.03346757, -2.29843906],\n",
      "       [ 4.3212177 ,  2.03415675, -2.29631719],\n",
      "       [ 4.31941562,  2.03475904, -2.29391416],\n",
      "       [ 4.31450806,  2.03654467, -2.28732256],\n",
      "       [ 4.31768627,  2.03549421, -2.29154432],\n",
      "       [ 4.31565832,  2.03620419, -2.28883591],\n",
      "       [ 4.31330859,  2.0370825 , -2.28566357],\n",
      "       [ 4.3121558 ,  2.0375687 , -2.28408313],\n",
      "       [ 4.31864834,  2.03465072, -2.29307844],\n",
      "       [ 4.28994111,  2.04624037, -2.25394022],\n",
      "       [ 4.29343325,  2.04483356, -2.25872033],\n",
      "       [ 4.30293894,  2.04083111, -2.27174563],\n",
      "       [ 4.301833  ,  2.04154167, -2.27010711],\n",
      "       [ 4.31589493,  2.03602472, -2.28919581],\n",
      "       [ 4.31657045,  2.03569137, -2.29014146],\n",
      "       [ 4.30034964,  2.04189465, -2.26822455],\n",
      "       [ 4.30042256,  2.04183037, -2.26833476],\n",
      "       [ 4.31227119,  2.03748181, -2.28425156],\n",
      "       [ 4.32072853,  2.0342635 , -2.29569781],\n",
      "       [ 4.32184215,  2.03386149, -2.2971878 ],\n",
      "       [ 4.30658874,  2.03939709, -2.27670411],\n",
      "       [ 4.31617763,  2.03559372, -2.28972269],\n",
      "       [ 4.32010718,  2.03436668, -2.294905  ],\n",
      "       [ 4.31744094,  2.03534849, -2.29133687],\n",
      "       [ 4.30114811,  2.04107765, -2.26957607],\n",
      "       [ 4.31390076,  2.0367499 , -2.28651783],\n",
      "       [ 4.31527312,  2.0361934 , -2.28838508],\n",
      "       [ 4.26931118,  2.05232497, -2.22694525],\n",
      "       [ 4.30555376,  2.03956627, -2.27544732],\n",
      "       [ 4.29182567,  2.04553752, -2.25648144],\n",
      "       [ 4.30081271,  2.04210628, -2.26864441],\n",
      "       [ 4.30135453,  2.04133108, -2.26965366],\n",
      "       [ 4.31603858,  2.03606073, -2.28935256],\n",
      "       [ 4.30605547,  2.03952323, -2.27603736],\n",
      "       [ 4.31817683,  2.0352041 , -2.29225768],\n",
      "       [ 4.31364926,  2.03674212, -2.28622685],\n",
      "       [ 0.61011805,  3.49256231,  2.74468051],\n",
      "       [ 0.16096953,  3.66905992,  3.3547793 ],\n",
      "       [-0.06421339,  3.75755214,  3.66065839],\n",
      "       [-0.15682656,  3.79385325,  3.78640361],\n",
      "       [-0.16383084,  3.79668954,  3.79596866],\n",
      "       [-0.26360033,  3.83587986,  3.93147924],\n",
      "       [-0.22509277,  3.82077187,  3.87918806],\n",
      "       [ 1.18327367,  3.26709803,  1.96598813],\n",
      "       [ 0.31031661,  3.61036549,  3.15191081],\n",
      "       [-0.12978683,  3.78326198,  3.74968996],\n",
      "       [ 0.43180129,  3.56226868,  2.98667967],\n",
      "       [ 0.03269292,  3.71945722,  3.52901658],\n",
      "       [ 0.77106718,  3.42919337,  2.52599084],\n",
      "       [-0.29925617,  3.84990552,  3.97992182],\n",
      "       [ 1.18201386,  3.26778396,  1.96782001],\n",
      "       [ 0.76087463,  3.4333158 ,  2.53989801],\n",
      "       [-0.40911671,  3.89307291,  4.12914674],\n",
      "       [ 0.90046876,  3.37841334,  2.35025289],\n",
      "       [-0.4670521 ,  3.91580978,  4.2078297 ],\n",
      "       [ 0.59913611,  3.49679572,  2.75954947],\n",
      "       [-0.59024403,  3.96426252,  4.37518954],\n",
      "       [ 0.8011568 ,  3.41746398,  2.48516797],\n",
      "       [-0.54968174,  3.94830798,  4.32008429],\n",
      "       [-0.11654   ,  3.77809688,  3.73172541],\n",
      "       [ 0.64799142,  3.47766571,  2.69322755],\n",
      "       [ 0.54083581,  3.51978121,  2.83878627],\n",
      "       [-0.06120257,  3.75636222,  3.65656509],\n",
      "       [-0.48045879,  3.92112268,  4.22606505],\n",
      "       [-0.28307234,  3.84354436,  3.95793747],\n",
      "       [ 2.06461586,  2.92089942,  0.76891149],\n",
      "       [ 0.57703871,  3.50545206,  2.7895496 ],\n",
      "       [ 1.04543309,  3.32136891,  2.153296  ],\n",
      "       [ 0.79904144,  3.41827537,  2.48802925],\n",
      "       [-0.65862891,  3.99112783,  4.4680757 ],\n",
      "       [-0.47466054,  3.91882587,  4.21817496],\n",
      "       [-0.14086616,  3.78767202,  3.76477754],\n",
      "       [ 0.04316662,  3.71535375,  3.51479781],\n",
      "       [-0.09973311,  3.77146238,  3.708881  ],\n",
      "       [ 0.29141309,  3.61777778,  3.17757647],\n",
      "       [-0.03407972,  3.74564414,  3.6196851 ],\n",
      "       [-0.26292316,  3.83558968,  3.93054421],\n",
      "       [-0.15673568,  3.79390124,  3.78633003],\n",
      "       [ 0.49443215,  3.5379713 ,  2.90179216],\n",
      "       [ 1.18744101,  3.26543857,  1.96031917],\n",
      "       [-0.07377589,  3.76127086,  3.6736226 ],\n",
      "       [ 0.42746248,  3.56431613,  2.99277502],\n",
      "       [ 0.14135855,  3.67674375,  3.38140322],\n",
      "       [ 0.43558898,  3.56113056,  2.98174267],\n",
      "       [ 2.01946373,  2.93854158,  0.83018061],\n",
      "       [ 0.20815522,  3.65048772,  3.290666  ],\n",
      "       [-0.75599195,  4.02940296,  4.60033798],\n",
      "       [-0.72081527,  4.01556715,  4.55254709],\n",
      "       [-0.73082809,  4.01951394,  4.56615669],\n",
      "       [-0.71948172,  4.01505098,  4.55074144],\n",
      "       [-0.74632588,  4.0256032 ,  4.58720733],\n",
      "       [-0.74781153,  4.02618888,  4.58922679],\n",
      "       [-0.6984709 ,  4.0067404 ,  4.52215896],\n",
      "       [-0.7290134 ,  4.01880043,  4.56369156],\n",
      "       [-0.73252785,  4.02017533,  4.56846178],\n",
      "       [-0.74464029,  4.02494331,  4.58491944],\n",
      "       [-0.64570676,  3.98606224,  4.45053086],\n",
      "       [-0.70825983,  4.01063885,  4.53549699],\n",
      "       [-0.71372677,  4.01279265,  4.54292643],\n",
      "       [-0.73330613,  4.02047035,  4.56951034],\n",
      "       [-0.74783232,  4.02618982,  4.58924934],\n",
      "       [-0.72668996,  4.01788693,  4.56053486],\n",
      "       [-0.69120781,  4.00394154,  4.51233653],\n",
      "       [-0.7383254 ,  4.02246204,  4.57634181],\n",
      "       [-0.75808621,  4.03022613,  4.60318322],\n",
      "       [-0.66805273,  3.99480473,  4.48086201],\n",
      "       [-0.73371248,  4.0206479 ,  4.57007492],\n",
      "       [-0.71939923,  4.01501003,  4.55062258],\n",
      "       [-0.74856823,  4.02648573,  4.5902544 ],\n",
      "       [-0.63178846,  3.98058417,  4.43161983],\n",
      "       [-0.72148208,  4.01584145,  4.55346151],\n",
      "       [-0.69036467,  4.00361342,  4.51119338],\n",
      "       [-0.60542404,  3.97022426,  4.39580779],\n",
      "       [-0.61861546,  3.97541101,  4.41372786],\n",
      "       [-0.74091286,  4.02347384,  4.57985316],\n",
      "       [-0.62629946,  3.97843615,  4.42416949],\n",
      "       [-0.72374168,  4.01672848,  4.55653057],\n",
      "       [-0.67892612,  3.99912004,  4.49565677],\n",
      "       [-0.74530305,  4.0251995 ,  4.58581683],\n",
      "       [-0.56319111,  3.95362733,  4.33844044],\n",
      "       [-0.69773121,  4.00649308,  4.52119026],\n",
      "       [-0.73658814,  4.02177845,  4.57398151],\n",
      "       [-0.74450081,  4.02488701,  4.5847288 ],\n",
      "       [-0.6914483 ,  4.00403645,  4.51266335],\n",
      "       [-0.60647156,  3.97063761,  4.39723128],\n",
      "       [-0.68983863,  4.00340585,  4.51047829],\n",
      "       [-0.74232994,  4.0240338 ,  4.58178009],\n",
      "       [-0.68228892,  4.00043906,  4.50022317],\n",
      "       [-0.72081527,  4.01556715,  4.55254709],\n",
      "       [-0.74458914,  4.02492214,  4.58484923],\n",
      "       [-0.74613284,  4.02552893,  4.5869462 ],\n",
      "       [-0.71411229,  4.01294395,  4.54344995],\n",
      "       [-0.69271948,  4.00452588,  4.51438421],\n",
      "       [-0.68379986,  4.00103055,  4.50227401],\n",
      "       [-0.73299616,  4.02036544,  4.56910101],\n",
      "       [-0.68265164,  4.00057478,  4.50071077]]), 'A2': array([[0.90616565, 0.0926098 , 0.00122454],\n",
      "       [0.90517286, 0.09357931, 0.00124783],\n",
      "       [0.90549907, 0.09326067, 0.00124026],\n",
      "       [0.90417262, 0.0945565 , 0.00127087],\n",
      "       [0.90616141, 0.09261399, 0.00122461],\n",
      "       [0.90582818, 0.09293989, 0.00123193],\n",
      "       [0.90486231, 0.09388305, 0.00125463],\n",
      "       [0.90570919, 0.09305579, 0.00123502],\n",
      "       [0.90340203, 0.0953086 , 0.00128938],\n",
      "       [0.90543896, 0.09331947, 0.00124157],\n",
      "       [0.90642289, 0.09235862, 0.00121849],\n",
      "       [0.90501006, 0.09373886, 0.00125108],\n",
      "       [0.90541258, 0.09334497, 0.00124245],\n",
      "       [0.90549991, 0.09325886, 0.00124122],\n",
      "       [0.90688948, 0.0919027 , 0.00120783],\n",
      "       [0.90669949, 0.0920885 , 0.00121201],\n",
      "       [0.90649391, 0.09228926, 0.00121684],\n",
      "       [0.90591969, 0.09285018, 0.00123013],\n",
      "       [0.90628299, 0.09249546, 0.00122155],\n",
      "       [0.90604797, 0.092725  , 0.00122703],\n",
      "       [0.90577026, 0.09299629, 0.00123345],\n",
      "       [0.90562905, 0.09313431, 0.00123663],\n",
      "       [0.906437  , 0.09234429, 0.00121871],\n",
      "       [0.90293115, 0.09576962, 0.00129922],\n",
      "       [0.90336362, 0.09534725, 0.00128914],\n",
      "       [0.90454679, 0.09419115, 0.00126207],\n",
      "       [0.90438877, 0.09434592, 0.00126531],\n",
      "       [0.90608358, 0.09269007, 0.00122635],\n",
      "       [0.90617008, 0.09260544, 0.00122448],\n",
      "       [0.90422811, 0.09450254, 0.00126935],\n",
      "       [0.90424004, 0.09449082, 0.00126914],\n",
      "       [0.90564643, 0.09311726, 0.0012363 ],\n",
      "       [0.9066485 , 0.09213822, 0.00121328],\n",
      "       [0.9067779 , 0.0920118 , 0.0012103 ],\n",
      "       [0.90498883, 0.09375931, 0.00125186],\n",
      "       [0.9061444 , 0.09263016, 0.00122544],\n",
      "       [0.9065864 , 0.09219868, 0.00121492],\n",
      "       [0.90627414, 0.09250377, 0.00122209],\n",
      "       [0.90436853, 0.09436464, 0.00126682],\n",
      "       [0.90584974, 0.09291848, 0.00123177],\n",
      "       [0.90601558, 0.09275641, 0.00122801],\n",
      "       [0.90053906, 0.09810196, 0.00135898],\n",
      "       [0.90488401, 0.09386141, 0.00125459],\n",
      "       [0.90315985, 0.09554634, 0.00129381],\n",
      "       [0.90425061, 0.09448113, 0.00126826],\n",
      "       [0.90436484, 0.0943687 , 0.00126646],\n",
      "       [0.90609296, 0.09268105, 0.00122599],\n",
      "       [0.90493151, 0.09381521, 0.00125328],\n",
      "       [0.90634974, 0.09243009, 0.00122017],\n",
      "       [0.90582862, 0.09293896, 0.00123241],\n",
      "       [0.03661499, 0.65386576, 0.30951925],\n",
      "       [0.01701676, 0.56809528, 0.41488796],\n",
      "       [0.01134421, 0.51825782, 0.47039797],\n",
      "       [0.00956429, 0.49706245, 0.49337327],\n",
      "       [0.00944007, 0.49545848, 0.49510145],\n",
      "       [0.00783282, 0.47238899, 0.51977819],\n",
      "       [0.00842036, 0.48131286, 0.51026678],\n",
      "       [0.08910638, 0.71598217, 0.19491145],\n",
      "       [0.02209601, 0.59911045, 0.37879354],\n",
      "       [0.01005528, 0.50328019, 0.48666453],\n",
      "       [0.02720762, 0.62263752, 0.35015486],\n",
      "       [0.01353008, 0.54005952, 0.44641041],\n",
      "       [0.04750022, 0.67780568, 0.2746941 ],\n",
      "       [0.00732269, 0.46411797, 0.52855934],\n",
      "       [0.0889287 , 0.71594617, 0.19512513],\n",
      "       [0.04673043, 0.6764353 , 0.27683427],\n",
      "       [0.00593861, 0.43863368, 0.55542771],\n",
      "       [0.05821081, 0.6936834 , 0.24810579],\n",
      "       [0.00531105, 0.4252389 , 0.56945005],\n",
      "       [0.03596297, 0.65206828, 0.31196875],\n",
      "       [0.00417658, 0.3970247 , 0.59879872],\n",
      "       [0.04982011, 0.6817929 , 0.26838699],\n",
      "       [0.00452229, 0.40626627, 0.58921144],\n",
      "       [0.01030399, 0.50631937, 0.48337665],\n",
      "       [0.03895457, 0.65988824, 0.30115718],\n",
      "       [0.03265751, 0.64227742, 0.32506507],\n",
      "       [0.01140697, 0.51894075, 0.46965228],\n",
      "       [0.00517474, 0.42215383, 0.57267144],\n",
      "       [0.00755025, 0.46787343, 0.52457632],\n",
      "       [0.2756264 , 0.64893327, 0.07544033],\n",
      "       [0.03467818, 0.6484106 , 0.31691122],\n",
      "       [0.07264851, 0.70738048, 0.21997101],\n",
      "       [0.0496544 , 0.68151679, 0.26882881],\n",
      "       [0.00364936, 0.38157549, 0.61477515],\n",
      "       [0.00523329, 0.42348871, 0.571278  ],\n",
      "       [0.00985079, 0.50074159, 0.48940761],\n",
      "       [0.01378796, 0.54238861, 0.44382343],\n",
      "       [0.01062839, 0.51015981, 0.4792118 ],\n",
      "       [0.02138517, 0.59529825, 0.38331658],\n",
      "       [0.011987  , 0.52507773, 0.46293528],\n",
      "       [0.00784297, 0.47254375, 0.51961329],\n",
      "       [0.00956527, 0.49709206, 0.49334268],\n",
      "       [0.03022612, 0.6341247 , 0.33564917],\n",
      "       [0.08965034, 0.71616781, 0.19418185],\n",
      "       [0.0111475 , 0.51608019, 0.47277231],\n",
      "       [0.02700075, 0.62186202, 0.35113723],\n",
      "       [0.01643572, 0.56388043, 0.41968385],\n",
      "       [0.02737464, 0.62338142, 0.34924395],\n",
      "       [0.26236962, 0.65775473, 0.07987566],\n",
      "       [0.01849356, 0.57810462, 0.40340182],\n",
      "       [0.00300576, 0.35993596, 0.63705828],\n",
      "       [0.00322485, 0.36770079, 0.62907436],\n",
      "       [0.00316098, 0.36548471, 0.63135431],\n",
      "       [0.00323342, 0.36799691, 0.62876967],\n",
      "       [0.00306452, 0.36206342, 0.63487207],\n",
      "       [0.00305541, 0.3617362 , 0.63520839],\n",
      "       [0.00337186, 0.37266333, 0.62396481],\n",
      "       [0.00317246, 0.36588606, 0.63094147],\n",
      "       [0.00315028, 0.36510823, 0.63174149],\n",
      "       [0.00307487, 0.36243511, 0.63449003],\n",
      "       [0.00374389, 0.38448141, 0.61177469],\n",
      "       [0.0033066 , 0.37048782, 0.62620557],\n",
      "       [0.00327075, 0.36927392, 0.62745533],\n",
      "       [0.00314541, 0.36493567, 0.63191892],\n",
      "       [0.0030553 , 0.36173126, 0.63521344],\n",
      "       [0.00318722, 0.36640029, 0.63041249],\n",
      "       [0.00342078, 0.37428511, 0.62229411],\n",
      "       [0.00311396, 0.36382826, 0.63305778],\n",
      "       [0.00299317, 0.35947557, 0.63753126],\n",
      "       [0.00358188, 0.37945875, 0.61695937],\n",
      "       [0.00314281, 0.36484709, 0.63201009],\n",
      "       [0.00323398, 0.36801479, 0.62875123],\n",
      "       [0.00305079, 0.36156946, 0.63537975],\n",
      "       [0.00384835, 0.38761711, 0.60853454],\n",
      "       [0.00322053, 0.36755385, 0.62922562],\n",
      "       [0.00342651, 0.37447346, 0.62210003],\n",
      "       [0.00405372, 0.39357948, 0.6023668 ],\n",
      "       [0.0039497 , 0.39059326, 0.60545704],\n",
      "       [0.0030979 , 0.3632568 , 0.6336453 ],\n",
      "       [0.00389026, 0.38885702, 0.60725272],\n",
      "       [0.00320604, 0.36705305, 0.62974091],\n",
      "       [0.0035053 , 0.37702865, 0.61946606],\n",
      "       [0.0030708 , 0.36228869, 0.63464051],\n",
      "       [0.00440426, 0.40318298, 0.59241276],\n",
      "       [0.0033767 , 0.37282985, 0.62379346],\n",
      "       [0.0031248 , 0.36421178, 0.63266342],\n",
      "       [0.00307573, 0.36246578, 0.63445849],\n",
      "       [0.00341914, 0.37423153, 0.62234933],\n",
      "       [0.00404536, 0.39334235, 0.60261229],\n",
      "       [0.0034301 , 0.37459076, 0.62197914],\n",
      "       [0.00308912, 0.36294443, 0.63396645],\n",
      "       [0.00348196, 0.37627665, 0.62024139],\n",
      "       [0.00322485, 0.36770079, 0.62907436],\n",
      "       [0.00307518, 0.3624463 , 0.63447851],\n",
      "       [0.0030657 , 0.36210607, 0.63482823],\n",
      "       [0.00326824, 0.36918833, 0.62754344],\n",
      "       [0.00341053, 0.37394701, 0.62264245],\n",
      "       [0.00347153, 0.37593887, 0.6205896 ],\n",
      "       [0.00314732, 0.3650054 , 0.63184728],\n",
      "       [0.00347948, 0.37619518, 0.62032534]])}\n"
     ]
    }
   ],
   "source": [
    "print(\"Using two layers [5,3] i.e one Hidden layer \")\n",
    "my_final_params = train_model(X,Y,500,0.1)\n",
    "print(my_final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more than 95% Accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
